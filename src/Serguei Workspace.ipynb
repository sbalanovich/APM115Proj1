{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Keyboard Biometrics\n",
    "\n",
    "## SVM Approach\n",
    "\n",
    "### Problem Background\n",
    "\n",
    "The problem explored in this project is the identification of a given user based on their typing patterns. Here, we used 3 datasets (found in the data folder under the names 'keystroke0' (the CMU dataset), 'keystroke1' (the standard dataset), 'keystroke2' (the multi-password dataset), and 'keystroke3' (the demographics dataset). The latter 3 come from the [GREYC](http://www.epaymentbiometrics.ensicaen.fr/greyc-keystroke-dataset) lab.\n",
    "\n",
    "In this project, we will run an SVM classifier on several configurations. First, we will attempt to use an n-class classifier, where n is the number of users in total for the dataset. Here we will try to precisely detect from the test set which of the n users it came from. \n",
    "\n",
    "Next, we will run a two-class classifier, in an attempt to determine with a simple binary whether the input provided has come from the genuine user or from one of the impostors. This is a simpler problem because it does not need to be as specific, but it is more practical for real-world applications as keyboard biometrics are really only interesting for ensuring that the typist of the password is in fact the authenticated user.\n",
    "\n",
    "Finally, we want to detect not only the proportion of time that the classifier gets the correct answer with respect to the genuine user and the impostor, but also to actually focus in on the false positives (when an impostor gets in) and the false negatives (when the genuine user is erroneously blocked from the system). For this portion, we will attempt to construct an ROC curve to visually present the true and false positive rates for the detections.\n",
    "\n",
    "### SVM Background\n",
    "\n",
    "Support vector machines (SVMs) are supervised learning models. Given a set of training examples, each marked for belonging to one of two categories, an SVM training algorithm encodes every input as some p-dimensional vector and computes a (p-1)-dimensional hyperplane to separate these points into two groups. New datapoints are then assigned a similar p-dimensional vector which then falls one one or the other side of the hyperplane and the point is thus classified. \n",
    "\n",
    "The SVM creates a margin spearating the data. The margin is defined by the distance from the hyperplane to the nearest point on either side of the hyperplane. If the data is linearly separable, it will be possible to create a \"hard amrgin\" meaning the data will be evenly split into two halves and there will be no data in the margin at all. This is a very good classifier but the data is not always this nice. More commonly, a \"soft margin\" is used which simply has a penalty factor on the points that fall within the margin and minimizes this penalty to determine the best hyperplane. \n",
    "\n",
    "The hyperplane's shape is determined by the \"kernel\" function used. The kernel can be linear, polynomial, or using a Gaussian radial basis function (rbf). Using a kernel will morph the plane from a linear shape to some curve which will often allow for better classification depending on the type of data and the parameters of the curve.\n",
    "\n",
    "For multi-class classification, we use the standard dual-class SVM but take a one vs all or a one vs one approach to detemine the one class that the given test data point fits best. In one vs all, n classifiers are created to compare the class x vs the other classes. The test point is run through each of these classifiers and the one with the highest probability of being in the class rather than being in the impostor group wins. In one vs one, each class is pitted against the others and a winner-takees-all strategy is employed until the best one is found.\n",
    "\n",
    "### SVM for Biometrics\n",
    "\n",
    "SVMs have been proven good for text categorization problems and bioinformatics. They are also known to perform well for large datasets. They are best for linearly separable data, though it's not certain whether the datasets looked at in this project have this quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(clf, X_test, y_test):\n",
    "    idx = 0\n",
    "    score = 0\n",
    "    for x in X_test:\n",
    "        y_pred = clf.predict([x])\n",
    "        if y_pred == y_test[idx]:\n",
    "            score += 1\n",
    "        idx+=1\n",
    "    return 100*score/idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_complex(clf,X_test,Y_test):\n",
    "    \n",
    "    count = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    user = Y_test.count(1)\n",
    "    imposter = Y_test.count(0)\n",
    "\n",
    "    for x in X_test:\n",
    "        \n",
    "        y_hat = clf.predict([x])\n",
    "        \n",
    "        if Y_test[count] == 1 and y_hat == 1:\n",
    "            tp += 1\n",
    "        if Y_test[count] == 1 and y_hat == 0:\n",
    "            fn += 1\n",
    "        if Y_test[count] == 0 and y_hat == 1:\n",
    "            fp += 1\n",
    "        if Y_test[count] == 0 and y_hat == 0:\n",
    "            tn += 1\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    return (round(tp/user*100,2),round(tn/imposter*100,2),round(fp/imposter*100,2),round(fn/user*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 - CMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "This is the basic dataset used in many keyboard biometrics studies. It contains 51 users and 20,400 total rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"../data/keystroke0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    first = 1\n",
    "    for row in reader:\n",
    "        if first:\n",
    "            first = 0\n",
    "            continue\n",
    "        X.append(row[3:])\n",
    "        Y.append(int(row[0][1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(C = 1)\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.13725490196079%\n"
     ]
    }
   ],
   "source": [
    "print(str(score(clf, X_test, y_test)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize the data with mean 0 and variance 1. We get a significantly better fit. We will normalize all datasets in this way from here on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.13725490196079%\n"
     ]
    }
   ],
   "source": [
    "X = preprocessing.scale(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(C = 1)\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "print(str(score(clf, X_test, y_test)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 25, 50, 75, 100]\n",
      "[39.38725490196079, 79.16666666666667, 82.0343137254902, 83.70098039215686, 84.46078431372548]\n"
     ]
    }
   ],
   "source": [
    "# Test different Csprint(str(score(clf, X_test, y_test)) + '%')\n",
    "results = []\n",
    "Cs = [1,25,50,75,100]\n",
    "\n",
    "for i in [1,25,50,75,100]:\n",
    "    results.append(score(svm.SVC(C = i).fit(X_train, y_train), X_test, y_test))\n",
    "    \n",
    "print(Cs)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear: 76.12745098039215%\n",
      "rbf: 39.38725490196079%\n",
      "poly: 2.2549019607843137%\n",
      "sigmoid: 1.3235294117647058%\n"
     ]
    }
   ],
   "source": [
    "# Test different kernels\n",
    "\n",
    "for i in ['linear','rbf','poly','sigmoid']:\n",
    "    print(i + ': ' + str(score(svm.SVC(kernel = i).fit(X_train, y_train), X_test, y_test)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genuine vs Impostor SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genuines = [2, 5, 13, 39]\n",
    "ys = []\n",
    "for g in genuines:\n",
    "    # Genuine = 1, Impostor = 0\n",
    "    newY = []\n",
    "    for elt in Y:\n",
    "        if elt == g:\n",
    "            newY.append(1)\n",
    "        else:\n",
    "            newY.append(0)\n",
    "    ys.append(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n",
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have exactly 400 1s in each list\n",
    "for i in range(len(genuines)):\n",
    "    print(sum(ys[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for y in ys:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    clf = svm.SVC(C = 1)\n",
    "    clf.fit(X_train, y_train) \n",
    "    scores.append(str(score(clf, X_test, y_test)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERY Weird. or maybe not that weird... they're not exactly the same, just very close, which kinda makes sense given what you were saying the other day. It's going to be almost entirely correct because there are so many 0s relative to 1s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['98.23529411764706%',\n",
       " '98.21078431372548%',\n",
       " '98.23529411764706%',\n",
       " '98.11274509803921%']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT2: \n",
      " True-Positive = 51.39% \n",
      " False-Negative = 48.61% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT3: \n",
      " True-Positive = 59.42% \n",
      " False-Negative = 40.58% \n",
      " True-Negative = 99.93% \n",
      " False-Positive = 0.07%\n",
      "SUBJECT4: \n",
      " True-Positive = 67.12% \n",
      " False-Negative = 32.88% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT5: \n",
      " True-Positive = 83.56% \n",
      " False-Negative = 16.44% \n",
      " True-Negative = 99.93% \n",
      " False-Positive = 0.07%\n",
      "SUBJECT7: \n",
      " True-Positive = 42.59% \n",
      " False-Negative = 57.41% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.02%\n",
      "SUBJECT8: \n",
      " True-Positive = 49.43% \n",
      " False-Negative = 50.57% \n",
      " True-Negative = 99.97% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT10: \n",
      " True-Positive = 84.54% \n",
      " False-Negative = 15.46% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT11: \n",
      " True-Positive = 78.67% \n",
      " False-Negative = 21.33% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT12: \n",
      " True-Positive = 75.27% \n",
      " False-Negative = 24.73% \n",
      " True-Negative = 99.97% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT13: \n",
      " True-Positive = 77.78% \n",
      " False-Negative = 22.22% \n",
      " True-Negative = 99.93% \n",
      " False-Positive = 0.07%\n",
      "SUBJECT15: \n",
      " True-Positive = 65.52% \n",
      " False-Negative = 34.48% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT16: \n",
      " True-Positive = 88.24% \n",
      " False-Negative = 11.76% \n",
      " True-Negative = 99.97% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT17: \n",
      " True-Positive = 87.8% \n",
      " False-Negative = 12.2% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT18: \n",
      " True-Positive = 75.34% \n",
      " False-Negative = 24.66% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.02%\n",
      "SUBJECT19: \n",
      " True-Positive = 88.75% \n",
      " False-Negative = 11.25% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT20: \n",
      " True-Positive = 56.98% \n",
      " False-Negative = 43.02% \n",
      " True-Negative = 99.85% \n",
      " False-Positive = 0.15%\n",
      "SUBJECT21: \n",
      " True-Positive = 61.63% \n",
      " False-Negative = 38.37% \n",
      " True-Negative = 99.82% \n",
      " False-Positive = 0.18%\n",
      "SUBJECT22: \n",
      " True-Positive = 94.44% \n",
      " False-Negative = 5.56% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT24: \n",
      " True-Positive = 90.41% \n",
      " False-Negative = 9.59% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT25: \n",
      " True-Positive = 89.41% \n",
      " False-Negative = 10.59% \n",
      " True-Negative = 99.9% \n",
      " False-Positive = 0.1%\n",
      "SUBJECT26: \n",
      " True-Positive = 54.84% \n",
      " False-Negative = 45.16% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT27: \n",
      " True-Positive = 81.93% \n",
      " False-Negative = 18.07% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT28: \n",
      " True-Positive = 87.06% \n",
      " False-Negative = 12.94% \n",
      " True-Negative = 99.97% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT29: \n",
      " True-Positive = 73.68% \n",
      " False-Negative = 26.32% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.02%\n",
      "SUBJECT30: \n",
      " True-Positive = 85.06% \n",
      " False-Negative = 14.94% \n",
      " True-Negative = 99.9% \n",
      " False-Positive = 0.1%\n",
      "SUBJECT31: \n",
      " True-Positive = 31.87% \n",
      " False-Negative = 68.13% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT32: \n",
      " True-Positive = 14.29% \n",
      " False-Negative = 85.71% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT33: \n",
      " True-Positive = 91.3% \n",
      " False-Negative = 8.7% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT34: \n",
      " True-Positive = 70.15% \n",
      " False-Negative = 29.85% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.02%\n",
      "SUBJECT35: \n",
      " True-Positive = 83.95% \n",
      " False-Negative = 16.05% \n",
      " True-Negative = 99.92% \n",
      " False-Positive = 0.08%\n",
      "SUBJECT36: \n",
      " True-Positive = 91.25% \n",
      " False-Negative = 8.75% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT37: \n",
      " True-Positive = 48.72% \n",
      " False-Negative = 51.28% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT38: \n",
      " True-Positive = 82.72% \n",
      " False-Negative = 17.28% \n",
      " True-Negative = 99.92% \n",
      " False-Positive = 0.08%\n",
      "SUBJECT39: \n",
      " True-Positive = 81.82% \n",
      " False-Negative = 18.18% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT40: \n",
      " True-Positive = 80.0% \n",
      " False-Negative = 20.0% \n",
      " True-Negative = 99.97% \n",
      " False-Positive = 0.03%\n",
      "SUBJECT41: \n",
      " True-Positive = 78.12% \n",
      " False-Negative = 21.88% \n",
      " True-Negative = 99.8% \n",
      " False-Positive = 0.2%\n",
      "SUBJECT42: \n",
      " True-Positive = 93.67% \n",
      " False-Negative = 6.33% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT43: \n",
      " True-Positive = 97.4% \n",
      " False-Negative = 2.6% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT44: \n",
      " True-Positive = 91.36% \n",
      " False-Negative = 8.64% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT46: \n",
      " True-Positive = 64.04% \n",
      " False-Negative = 35.96% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT47: \n",
      " True-Positive = 69.01% \n",
      " False-Negative = 30.99% \n",
      " True-Negative = 99.83% \n",
      " False-Positive = 0.17%\n",
      "SUBJECT48: \n",
      " True-Positive = 67.12% \n",
      " False-Negative = 32.88% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT49: \n",
      " True-Positive = 81.48% \n",
      " False-Negative = 18.52% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT50: \n",
      " True-Positive = 61.8% \n",
      " False-Negative = 38.2% \n",
      " True-Negative = 99.85% \n",
      " False-Positive = 0.15%\n",
      "SUBJECT51: \n",
      " True-Positive = 70.67% \n",
      " False-Negative = 29.33% \n",
      " True-Negative = 99.95% \n",
      " False-Positive = 0.05%\n",
      "SUBJECT52: \n",
      " True-Positive = 93.18% \n",
      " False-Negative = 6.82% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT53: \n",
      " True-Positive = 93.06% \n",
      " False-Negative = 6.94% \n",
      " True-Negative = 99.98% \n",
      " False-Positive = 0.02%\n",
      "SUBJECT54: \n",
      " True-Positive = 60.24% \n",
      " False-Negative = 39.76% \n",
      " True-Negative = 99.9% \n",
      " False-Positive = 0.1%\n",
      "SUBJECT55: \n",
      " True-Positive = 93.85% \n",
      " False-Negative = 6.15% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT56: \n",
      " True-Positive = 66.67% \n",
      " False-Negative = 33.33% \n",
      " True-Negative = 100.0% \n",
      " False-Positive = 0.0%\n",
      "SUBJECT57: \n",
      " True-Positive = 63.44% \n",
      " False-Negative = 36.56% \n",
      " True-Negative = 99.92% \n",
      " False-Positive = 0.08%\n"
     ]
    }
   ],
   "source": [
    "true_positives = []\n",
    "false_negatives = []\n",
    "true_negatives = []\n",
    "false_negatives = []\n",
    "\n",
    "for i in [x for x in range(2,58) if x in Y]:\n",
    "\n",
    "    user = [1 if x == i else 0 for x in Y]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, user, test_size=0.2, random_state=42)\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train,Y_train)\n",
    "        \n",
    "    scores = score_complex(clf,X_test,Y_test)\n",
    "    \n",
    "    true_positives.append(scores[0])\n",
    "    false_negatives.append(scores[3])\n",
    "    true_negatives.append(scores[1])\n",
    "    false_negatives.append(scores[2])\n",
    "\n",
    "    print('SUBJECT' + str(i) + ': \\n True-Positive = ' + str(scores[0]) + '% \\n False-Negative = ' + str(scores[3]) + '% \\n True-Negative = ' + str(scores[1]) + '% \\n False-Positive = ' + str(scores[2]) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the basic code for creating some ROC curves. In this test I just made 6 different \"folds\", or cross-validation splits and compared them against each other. Ideally we would be comparing different C values, kernels, and datasets using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEZCAYAAACervI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wHbRYlD/6yulgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a9ace48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gonna just use the first y since it doesn't seem to matter\n",
    "yyy = np.array(ys[0])\n",
    "XXX = np.array(X)\n",
    "\n",
    "# More intense cross-validation\n",
    "cv = StratifiedKFold(yyy, n_folds=6)\n",
    "classifier = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    probas_ = classifier.fit(XXX[train], yyy[train]).predict_proba(XXX[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(yyy[test], probas_[:, 1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 - GREYC Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "This is the standard GREYC dataset. It contains 133 users and 7,555 total rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"../data/keystroke1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    first = 1\n",
    "    for row in reader:\n",
    "        if first:\n",
    "            first = 0\n",
    "            continue\n",
    "        rw = list(map(lambda x: x/10000000., (map(int, row[5].split(' ')[1:61]))))\n",
    "        if len(rw) < 60:\n",
    "            continue\n",
    "        X.append(rw)\n",
    "        y.append(int(row[0]))\n",
    "\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(C = 1)\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####This actually takes a stupid long time to run.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-dff672f23ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-26c46b32af90>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(clf, X_test, y_test)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/justin/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \"\"\"\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/justin/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/justin/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(str(score(clf, X_test, y_test)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Well this is a bit awkward.. The data is very strange - I divided everything by 10,000,000 because the numbers were huge (I suspect they were in milliseconds), but still unclear why this took so long and yielded 0.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4 - GREYC Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "This is the GREYC dataset where users are also classfified by demographics. It contains 110 users and each has a binary class assigned to them based on age (younger or older than 30), gender, and handedness.\n",
    "\n",
    "The data is actually split into 2 files - 'keystroke3-1.csv' and 'keystroke3-2.csv'\n",
    "\n",
    "Each of these has the typing of a different password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"../data/keystroke3-1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    first = 1\n",
    "    for row in reader:\n",
    "        if first:\n",
    "            first = 0\n",
    "            continue\n",
    "        rw = list(map(lambda x: x/10000000., (map(int, row[6].split(' ')[1:61]))))\n",
    "        if len(rw) < 5:\n",
    "            print(rw)\n",
    "        X.append(rw)\n",
    "        y.append(int(row[0]))\n",
    "\n",
    "# normalize with mean 0 and variance 1\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(C = 1)\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "print(str(score(clf, X_test, y_test)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This one goes a lot faster but still.. 3%, what? -- better after normalizing but still really low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 - GREYC Multi-password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "This is the GREYC dataset where users typed multiple passwords. It contains 118 users, each with a unique password. This dataset is complex in its organization and should only be used as a stretch goal - for each password it has the user info for that password and also impostor info for trying to get at the password. Everything here lives in keystroke3.tar.gz\n",
    "\n",
    "The dataset is [here](http://www.epaymentbiometrics.ensicaen.fr/greyc-web-based-keystroke-dynamics-dataset) and the associated paper that uses this dataset can he found [here](http://arxiv.org/pdf/1207.0784.pdf) \n",
    "\n",
    "It's not worth looking into this until we've done good work on the other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IGNORE BELOW THIS POINT, ALL SCRATCHWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"../data/DSL-StrongPasswordData.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "specs = []\n",
    "users = []\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    first = 1\n",
    "    for row in reader:\n",
    "        if first:\n",
    "            first = 0\n",
    "            continue\n",
    "        specs.append(row[3:])\n",
    "        users.append(int(row[0][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(specs, users, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(specs, users, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "score = 0\n",
    "for x in X_test:\n",
    "    y_pred = clf.predict([x])\n",
    "    if y_pred == y_test[idx]:\n",
    "        score += 1\n",
    "    idx+=1\n",
    "print str(100*score/idx) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print score, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_specs = np.array(X_train).astype(np.float).ravel()\n",
    "np_users = np.array(y_train)\n",
    "print np_specs\n",
    "print np_users\n",
    "h = 0.02\n",
    "x_min, x_max = np_specs.min() - 15, np_specs.max() + 16\n",
    "y_min, y_max = np_users.min() - 15, np_users.max() + 16\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "specs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(specs, users, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
